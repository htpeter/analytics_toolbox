{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to `analytics_toolbox` aka `atb`\n",
    "\n",
    "### Enabling Data Scientists to amplify their inner Data Engineer.\n",
    "\n",
    "> A toolbox for managing data coming from multiple Postgres, Redshift & S3 data sources while performing Analytics and Research. We also have some functionality that help users build Slack Bots. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Install Us](https://pypi.org/project/analytics-toolbox/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pip install analytics_toolbox`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Documentation](https://htpeter.github.io/analytics_toolbox/)\n",
    "\n",
    "Our docs are currently useless as of 2020-02-12."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Vote For Change!](https://github.com/htpeter/analytics_toolbox/issues)\n",
    "\n",
    "I'll see your comments on GitHub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Us\n",
    "\n",
    "Coming someday, maybe?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do You Know About config Files?\n",
    "\n",
    "`analytics_toolbox` is only made possible by its reliance on standardized credential storage. You wanna use us, you sadly must play by some of our rules.  \n",
    "\n",
    "We read and build classes via the variable names in the config files you pass to our code. Trust us. Its worth it. You'll end up saving 100s of lines of code by simply passing 1 to 2 arguments when instantiating our primary classes.\n",
    "\n",
    "[Config Files](https://en.wikipedia.org/wiki/Configuration_file) are a great way to store information. We chose this over other options like json or OS level environment variables for no clear reason. If you really want support for other credential formats, [vote with your words here](https://github.com/htpeter/analytics_toolbox/issues/1).\n",
    "\n",
    "\n",
    "## Config File Format Guidelines\n",
    "\n",
    "### Postgres + Redshift Connections\n",
    "\n",
    "If your config file section has a `hostname`, `port`, `database` and `user` sections, then we'll parse it as a Redshift/Postgres database. You store your password in `.pgpass` (see below if this is new).\n",
    "\n",
    "Here is an example of Postgres/Redshift entries.\n",
    "`\"`\"\n",
    "```\n",
    "[dev_db]\n",
    "hostname = dev.yourhost.com\n",
    "port = 5432\n",
    "database = dbname \n",
    "user = htpeter\n",
    "\n",
    "[prod_db]\n",
    "hostname = prod.yourhost.com\n",
    "port = 5432\n",
    "database = dbname \n",
    "user = htpeter\n",
    "```\n",
    "\n",
    "#### What is .pgpass?\n",
    "\n",
    "When python's `psycopg2` or even `psql` attempt to connect to a server, they will look in a file called  `~/.pgpass`. If they find matching server information, based on the target they are connecting  to, they use that password.\n",
    "\n",
    "`~/.pgpass`'s format is simple. Include a line in the file that follows the following format.\n",
    "```\n",
    "hostname:port:database:username:password\n",
    "```\n",
    "\n",
    "Ensure you limit the permissions on this file using `chmod 600 ~/.pgpass`, otherwise no tools will use it due to its insecurity.\n",
    "\n",
    "You don't pass database passwords to `analytics_toolbox`. Instead we leverage [pgpass](https://www.postgresql.org/docs/9.3/libpq-pgpass.html). Simply paste a record for each database in a text file `~/.pgpass` with the following information.\n",
    "\n",
    "\n",
    "### Slack Connections \n",
    "\n",
    "Our Slack APIs use [Slack Bot OAuth Tokens](https://slack.com/help/articles/215770388-Create-and-regenerate-API-tokens#bot-user-tokens). \n",
    "\n",
    "Create an OAuth token and save it to a variable called `bot_user_oauth_token`. You can store the token in a config section named whatever you want.\n",
    "\n",
    "```\n",
    "[company_slack]\n",
    "oauth_token = 943f-1ji23ojf-43gjio3j4gio2-2fjoi23jfi23hio\n",
    "\n",
    "[personal_slack]\n",
    "oauth_token = 943f-dfase3-basf234234-fw4230kf230kf023k023\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying Multiple Databases & Moving Data\n",
    "\n",
    "Our import is both useful and classy enough to be jammed up at the top with your`pd`s, `np`s  and `plt`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import analytics_toolbox as atb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then you simply create a database pool object with your Config File. It loads up all the goodies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{   'dev_db': <analytics_toolbox.connector.DatabaseConnection object at 0x11698bc88>,\n",
       "    'prod_db': <analytics_toolbox.connector.DatabaseConnection object at 0x1169d8198>}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = atb.DBConnector('../atb_config_template.ini')\n",
    "\n",
    "db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can query any of our databasese easily!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference with the config file keyname \n",
    "db['dev_db'].qry('select * from pg_class limit 5')\n",
    "db['prod_db'].qry('select * from pg_class limit 5')\n",
    "\n",
    "# or if config file section is pythonic, use its name just like pandas!\n",
    "db.dev_db.qry('select * from pg_class limit 5')\n",
    "db.prod_db.qry('select * from pg_class limit 5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
