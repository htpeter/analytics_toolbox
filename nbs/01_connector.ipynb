{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp connector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `connector`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import logging\n",
    "import calendar\n",
    "import glob\n",
    "import json\n",
    "from io import StringIO\n",
    "import configparser\n",
    "\n",
    "import psycopg2\n",
    "import psycopg2.extras as extras\n",
    "import pandas as pd\n",
    "\n",
    "from analytics_toolbox import s3funcs\n",
    "\n",
    "class LocalLog(object):\n",
    "    \"\"\"\n",
    "    Creates a local logfile where these classes are imported,\n",
    "    showing database connections and what was run on databases.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, logname, log_path):\n",
    "        self.logger = logging.getLogger(logname)\n",
    "        self.logger.setLevel(logging.DEBUG)\n",
    "        # Create a logfile in log_path.\n",
    "        self.fh = logging.FileHandler((log_path + logname + \".log\").replace(\"//\", \"/\"))\n",
    "        self.fh.setLevel(logging.DEBUG)\n",
    "        formatter = logging.Formatter(\n",
    "            '{\"time\": %(asctime)s,\"name\" : %(name)s,'\n",
    "            '\"level\" : %(levelname)s, \"detail\" : %(message)s}'\n",
    "        )\n",
    "        self.fh.setFormatter(formatter)\n",
    "        self.logger.addHandler(self.fh)\n",
    "\n",
    "    def debug(self, message):\n",
    "        self.logger.debug(message)\n",
    "\n",
    "    def info(self, message):\n",
    "        self.logger.info(message)\n",
    "\n",
    "\n",
    "class StreamLog(object):\n",
    "    \"\"\"\n",
    "    Logs to STDOUT, useful for scripts that query DBs.\n",
    "    Every query will print JSON with information about SQL ran. \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, logname):\n",
    "        self.logger = logging.getLogger(logname)\n",
    "        self.logger.setLevel(logging.DEBUG)\n",
    "        self.fh = logging.StreamHandler(sys.stdout)\n",
    "        self.fh.setLevel(logging.DEBUG)\n",
    "        formatter = logging.Formatter(\n",
    "            '{\"time\": %(asctime)s,\"name\" : %(name)s,'\n",
    "            '\"level\" : %(levelname)s, \"detail\" : %(message)s}'\n",
    "        )\n",
    "        self.fh.setFormatter(formatter)\n",
    "        self.logger.addHandler(self.fh)\n",
    "\n",
    "    def debug(self, message):\n",
    "        print(message)\n",
    "\n",
    "    def info(self, message):\n",
    "        print(message)\n",
    "\n",
    "\n",
    "class DBConnector(object):\n",
    "    \"\"\"\n",
    "    Object that stores connections to many databases, which are created\n",
    "    from a .ini file that is passed as an object.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config_file, log=StreamLog(\"default-stream-log\")):\n",
    "        filetype = config_file.split(\".\")[-1]\n",
    "        if filetype == \"ini\":\n",
    "            self.config = configparser.RawConfigParser()\n",
    "            self.config.read(config_file)\n",
    "        if filetype == \"json\":\n",
    "            with open(config_file, \"r\") as f:\n",
    "                self.config = json.loads(f.read())\n",
    "        self.log = log\n",
    "        self.active_connections = {}\n",
    "        # Run func and initialize objects on self\n",
    "        self._init_database_objects()\n",
    "\n",
    "    def _init_database_objects(self):\n",
    "        criteria = [\"port\", \"database\", \"user\", \"hostname\"]\n",
    "        # review sections in config for db sections\n",
    "        for section in self.config.sections():\n",
    "            n = self.config.options(section)\n",
    "            # if the section has the criteria, store them\n",
    "            if set(criteria).issubset(set(n)):\n",
    "                bkt = {}\n",
    "                for i in criteria:\n",
    "                    p = self.config.get(section, i)\n",
    "                    bkt[i] = p\n",
    "                # allows db.section referencing\n",
    "                setattr(\n",
    "                    self, section.replace(\"-\", \"\"), DatabaseConnection(bkt, self.log)\n",
    "                )\n",
    "                self.active_connections[section] = DatabaseConnection(bkt, self.log)\n",
    "        # Check if configuration file has proper sections\n",
    "        if len(self.active_connections) == 0:\n",
    "            raise Exception(\n",
    "                \"\"\"\\n\n",
    "                Configuration file contained no Postgres sections. Please review\n",
    "                and format like below example :\n",
    "                    [db_shortname]\n",
    "                    hostname = host.com\n",
    "                    port = 5432\n",
    "                    database = dbname (default e.g postgres)\n",
    "                    user = htpeter (thats my name :))\n",
    "                \"\"\"\n",
    "            )\n",
    "\n",
    "    def close_all_conns(self):\n",
    "        counter = 0\n",
    "        conns = []\n",
    "        for i in self.active_connections.keys():\n",
    "            adj = i.replace(\"-\", \"\")\n",
    "            obj = getattr(self, adj)\n",
    "            try:\n",
    "                obj.conn.close()\n",
    "                conns.append(adj)\n",
    "                counter += 1\n",
    "            except Exception as e:\n",
    "                pass\n",
    "        print(\"\\n\\t Closed {0} connections.\\n\\t {1} \".format(str(counter), str(conns)))\n",
    "\n",
    "    def __repr__(self):\n",
    "        from pprint import pformat\n",
    "\n",
    "        return pformat(self.active_connections, indent=4)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.active_connections[item]\n",
    "\n",
    "\n",
    "class DatabaseConnection(object):\n",
    "    \"\"\"\n",
    "    Built on psycopg2 connections, provides high level API\n",
    "    for running queries and returning necessary information.\n",
    "    Implemented as an object on DBConnector.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, credentials, log):\n",
    "        self.cred = credentials\n",
    "        self.log = log\n",
    "\n",
    "    def _connect(self):\n",
    "        try:\n",
    "            conn = psycopg2.connect(\n",
    "                host=self.cred[\"hostname\"],\n",
    "                port=self.cred[\"port\"],\n",
    "                database=self.cred[\"database\"],\n",
    "                user=self.cred[\"user\"],\n",
    "                cursor_factory=extras.RealDictCursor,\n",
    "            )\n",
    "            self.log.info(\"Connected to {}\".format(self.cred[\"hostname\"]))\n",
    "            return conn\n",
    "        except Exception as e:\n",
    "            self.log.debug(e)\n",
    "\n",
    "    def _execute(self, sql, commit=False):\n",
    "        \"\"\"\n",
    "        Private function focused on handling the nitty gritty of running a psycopg2\n",
    "        execute and returning the results based on \"commit\" boolean.\n",
    "        \"\"\"\n",
    "        if commit == False:\n",
    "            try:\n",
    "                # Time the query and get results, log info\n",
    "                cur = self.conn.cursor()\n",
    "                t0 = time.time()\n",
    "                try:\n",
    "                    cur.execute(sql)\n",
    "                except Exception as e:\n",
    "                    self.conn.rollback()\n",
    "                    cur.execute(sql)\n",
    "                runtime = time.time() - t0\n",
    "                resp = cur.fetchall()\n",
    "                cur.close()\n",
    "                detail = '{{\"database\" : \"{0}\",\"runtime\" : {2},\\n \"sql\" : \"{1}\"}}'.format(\n",
    "                    self.cred[\"hostname\"], sql, str(runtime)\n",
    "                )\n",
    "                self.log.info(detail)\n",
    "                return resp\n",
    "\n",
    "            except Exception as e:\n",
    "                detail = '{{\"database\" : {0},\"error\" : \"{2}\",\\n \"sql\" : \"{1}\"}}'.format(\n",
    "                    self.cred[\"hostname\"], sql, e\n",
    "                )\n",
    "                self.log.debug(detail)\n",
    "                return e\n",
    "        else:\n",
    "            try:\n",
    "                # Time the query and get the ROWCOUNT, log info\n",
    "                cur = self.conn.cursor()\n",
    "                t0 = time.time()\n",
    "                try:\n",
    "                    cur.execute(sql)\n",
    "                except Exception as e:\n",
    "                    self.conn.rollback()\n",
    "                    cur.execute(sql)\n",
    "                runtime = time.time() - t0\n",
    "                self.conn.commit()\n",
    "                resp = str(cur.rowcount)\n",
    "                detail = '{{\"database\" : \"{0}\",\"row_count\" : {2}, \"runtime\" : {3},\\n \"sql\" : \"{1}\"}}'.format(\n",
    "                    self.cred[\"hostname\"], sql, resp, str(runtime)\n",
    "                )\n",
    "                self.log.info(detail)\n",
    "                cur.close()\n",
    "                return resp\n",
    "\n",
    "            except Exception as e:\n",
    "                detail = '{{\"database\" : \"{0}\", \"error\" : \"{2}\",\\n \"sql\" : \"{1}\"}}'.format(\n",
    "                    self.cred[\"hostname\"], sql, e\n",
    "                )\n",
    "                self.log.debug(detail)\n",
    "                return e\n",
    "\n",
    "    def get_pg_cursor(self, cursor_type=None):\n",
    "        conn = self._connect()\n",
    "        return conn, conn.cursor(cursor_factory=cursor_type)\n",
    "\n",
    "    def qry(self, sql, commit=False):\n",
    "        \"\"\"\n",
    "        Runs a query. Creates connection if non-existent.\n",
    "        \"\"\"\n",
    "        if hasattr(self, \"conn\"):\n",
    "            try:\n",
    "                resp = self._execute(sql, commit)\n",
    "                if commit: return resp\n",
    "                else: return pd.DataFrame(resp)\n",
    "            except ValueError as e:\n",
    "                print(sql)\n",
    "                raise Exception(e)\n",
    "\n",
    "        else:\n",
    "            self.conn = self._connect()\n",
    "            resp = self._execute(sql, commit)\n",
    "            if commit:\n",
    "                return True\n",
    "            else:\n",
    "                return pd.DataFrame(resp)\n",
    "\n",
    "    def write_df_to_table(self, \n",
    "                          dataframe: pd.DataFrame,\n",
    "                          create_statement: str, \n",
    "                          schema: str, \n",
    "                          tablename: str, \n",
    "                          columns: tuple,\n",
    "                          db_engine: str,\n",
    "                          s3_bucket: str,\n",
    "                          append = True) -> int:\n",
    "        \"\"\"\n",
    "        Writes a dataframe to the target table using the create_statement.\n",
    "        Its best practice to add CREATE TABLE IF NOT EXISTS to your statement. \n",
    "        DROPS should be done seperately and explicity from this process.\n",
    "        \"\"\"\n",
    "        # create the table if it does not exist\n",
    "        if not self.qry(create_statement, commit = True):\n",
    "            raise Exception(f'Error writing {schema}.{tablename} to {self.cred[\"hostname\"]}')\n",
    "        # delete table results if append does not exist\n",
    "        if not append:\n",
    "            self.qry(f\"DELETE FROM {schema}.{tablename}\", commit = True)\n",
    "\n",
    "        if db_engine == 'postgres':\n",
    "            # prepare dataframe for efficent write\n",
    "            stream = StringIO()\n",
    "            dataframe.to_csv(stream, sep=\"\\t\", header=False, index=False, float_format='%.0f')\n",
    "            # move to beginning of stream\n",
    "            stream.seek(1)\n",
    "            contents = stream.getvalue()\n",
    "            # create psycopg2 cursor\n",
    "            cur = self.conn.cursor()\n",
    "            try:\n",
    "                cur.copy_from(\n",
    "                    stream, \n",
    "                    f'{schema}.{tablename}', \n",
    "                    null=\"\", \n",
    "                    columns=columns\n",
    "                )\n",
    "                self.conn.commit()\n",
    "            except psycopg2.errors.InFailedSqlTransaction as e:\n",
    "                self.conn.rollback()\n",
    "                raise Exception(f'Error copying to {schema}.{tablename}. Transaction block failed.')\n",
    "            # close cursor after job is complete\n",
    "            cur.close()\n",
    "            return True\n",
    "        elif db_engine == 'redshift':\n",
    "            # write dataframe to S3 bucket, also get credentials \n",
    "            bucket = s3funcs.S3Bucket(s3_bucket)\n",
    "            bucket.write_dataframe(dataframe, f'atb-writer/{tablename}.tsv')\n",
    "            access_key = bucket.aws_access_key_id\n",
    "            secret_access_key = bucket.aws_secret_access_key\n",
    "            # copy \n",
    "            load = f\"\"\"\n",
    "            COPY {schema}.{tablename}\n",
    "            FROM 's3://{s3_bucket}/atb-writer/{tablename}.tsv'\n",
    "            CREDENTIALS 'aws_access_key_id={access_key};aws_secret_access_key={secret_access_key}'\n",
    "            DELIMITER '\\t';\n",
    "            \"\"\"\n",
    "            self.qry(load, commit = True)\n",
    "            # delete from s3 \n",
    "            bucket.bucket.Object(\"atb-writer/{tablename}.tsv\").delete()\n",
    "            return True\n",
    "\n",
    "\n",
    "def move_table(table, from_db, to_db):\n",
    "    assert type(from_db) == DatabaseConnection\n",
    "    assert type(to_db) == DatabaseConnection\n",
    "    creds = {\n",
    "        \"from_host\": from_db.cred[\"hostname\"],\n",
    "        \"from_db\": from_db.cred[\"database\"],\n",
    "        \"from_user\": from_db.cred[\"user\"],\n",
    "        \"to_host\": to_db.cred[\"hostname\"],\n",
    "        \"to_db\": to_db.cred[\"database\"],\n",
    "        \"to_user\": to_db.cred[\"user\"],\n",
    "        \"table\": table,\n",
    "    }\n",
    "    os.system(\n",
    "        \"pg_dump -t {table} -h {from_host} -U {from_user} {from_db} | psql -h {to_host} -U {to_user} {to_db}\".format(\n",
    "            **creds\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def current_datetime_dict(current_time=datetime.datetime.now()):\n",
    "    cy = datetime.datetime.now().year\n",
    "    cm = datetime.datetime.now().strftime(\"%m\")\n",
    "    now = current_time\n",
    "\n",
    "    if now.month == 1:\n",
    "        pm_d = datetime.datetime(now.year - 1, 12, 1)\n",
    "        pm = datetime.datetime(now.year - 1, 12, 1).strftime(\"%m\")\n",
    "        mrange = calendar.monthrange(pm_d.year, pm_d.month)\n",
    "        iso_mstart = str(datetime.datetime(pm_d.year, pm_d.month, 1))\n",
    "        iso_mend = str(datetime.datetime(pm_d.year, pm_d.month, mrange[1]))\n",
    "    else:\n",
    "        pm_d = datetime.datetime(now.year, now.month - 1, 1)\n",
    "        pm = datetime.datetime(now.year, now.month - 1, 1).strftime(\"%m\")\n",
    "        mrange = calendar.monthrange(pm_d.year, pm_d.month)\n",
    "        iso_mstart = str(datetime.datetime(pm_d.year, pm_d.month, 1))\n",
    "        iso_mend = str(datetime.datetime(pm_d.year, pm_d.month, mrange[1]))\n",
    "\n",
    "    data = {\n",
    "        \"now\": str(now),\n",
    "        \"past_iso_start\": iso_mstart,\n",
    "        \"past_iso_end\": iso_mend,\n",
    "        \"current_yearmo\": str(now.year) + str(now.strftime(\"%m\")),\n",
    "        \"past_yearmo\": str(pm_d.year) + str(pm),\n",
    "        \"current_year_mm\": str(now.year) + \"-\" + str(now.strftime(\"%m\")),\n",
    "        \"past_year_mm\": str(pm_d.year) + \"-\" + str(pm_d.strftime(\"%m\")),\n",
    "    }\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "class NativeTemplateEnvironment(object):\n",
    "    \"\"\"\n",
    "    Reads files from a folder, passed during initialization, and injects values \n",
    "    from a dictionary. Usings Python native string functions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, templates_folder):\n",
    "        self.path = templates_folder\n",
    "\n",
    "    def build(self, template_name, context):\n",
    "        complete_path = self.path + \"/\" + template_name\n",
    "        # In case user passes trailing / in self.path\n",
    "        complete_path = complete_path.replace(\"//\", \"/\")\n",
    "        f = open(complete_path, \"r\")\n",
    "        skeleton = f.read()\n",
    "        f.close()\n",
    "        sql = skeleton.format(**context)\n",
    "        return sql\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
