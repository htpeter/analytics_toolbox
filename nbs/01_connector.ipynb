{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# default_exp connector \n",
    "# default_cls_lvl 3\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# not a dep but we need it for show_doc\n",
    "\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import time\n",
    "from pprint import pformat\n",
    "\n",
    "from io import StringIO\n",
    "import configparser\n",
    "\n",
    "import psycopg2\n",
    "import psycopg2.extras as extras\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "\n",
    "from analytics_toolbox.logtools import *\n",
    "from analytics_toolbox.s3funcs import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `connector`\n",
    "\n",
    "Connectors are pretty damn useful for those of us who love databases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class DatabaseConnection(object):\n",
    "    \"\"\"\n",
    "    Built on psycopg2 connections, provides high level API\n",
    "    for running queries and returning necessary information.\n",
    "    Implemented as an object on DBConnector.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, credentials, log):\n",
    "        self.cred = credentials\n",
    "        self.log = log\n",
    "\n",
    "    def _connect(self):\n",
    "        try:\n",
    "            conn = psycopg2.connect(\n",
    "                host=self.cred[\"hostname\"],\n",
    "                port=self.cred[\"port\"],\n",
    "                database=self.cred[\"database\"],\n",
    "                user=self.cred[\"user\"],\n",
    "                cursor_factory=extras.RealDictCursor,\n",
    "            )\n",
    "            self.log.info(\"Connected to {}\".format(self.cred[\"hostname\"]))\n",
    "            return conn\n",
    "        except Exception as e:\n",
    "            self.log.debug(e)\n",
    "\n",
    "    def _execute(self, sql, commit=False):\n",
    "        \"\"\"\n",
    "        Private function focused on handling the nitty gritty of running a psycopg2\n",
    "        execute and returning the results based on \"commit\" boolean.\n",
    "        \"\"\"\n",
    "        if commit == False:\n",
    "            try:\n",
    "                # Time the query and get results, log info\n",
    "                cur = self.conn.cursor()\n",
    "                t0 = time.time()\n",
    "                try:\n",
    "                    cur.execute(sql)\n",
    "                except Exception as e:\n",
    "                    self.conn.rollback()\n",
    "                    cur.execute(sql)\n",
    "                runtime = time.time() - t0\n",
    "                resp = cur.fetchall()\n",
    "                cur.close()\n",
    "                detail = '{{\"database\" : \"{0}\",\"runtime\" : {2},\\n \"sql\" : \"{1}\"}}'.format(\n",
    "                    self.cred[\"hostname\"], sql, str(runtime)\n",
    "                )\n",
    "                self.log.info(detail)\n",
    "                return resp\n",
    "\n",
    "            except Exception as e:\n",
    "                detail = '{{\"database\" : {0},\"error\" : \"{2}\",\\n \"sql\" : \"{1}\"}}'.format(\n",
    "                    self.cred[\"hostname\"], sql, e\n",
    "                )\n",
    "                self.log.debug(detail)\n",
    "                return e\n",
    "        else:\n",
    "            try:\n",
    "                # Time the query and get the ROWCOUNT, log info\n",
    "                cur = self.conn.cursor()\n",
    "                t0 = time.time()\n",
    "                try:\n",
    "                    cur.execute(sql)\n",
    "                except Exception as e:\n",
    "                    self.conn.rollback()\n",
    "                    cur.execute(sql)\n",
    "                runtime = time.time() - t0\n",
    "                self.conn.commit()\n",
    "                resp = str(cur.rowcount)\n",
    "                detail = '{{\"database\" : \"{0}\",\"row_count\" : {2}, \"runtime\" : {3},\\n \"sql\" : \"{1}\"}}'.format(\n",
    "                    self.cred[\"hostname\"], sql, resp, str(runtime)\n",
    "                )\n",
    "                self.log.info(detail)\n",
    "                cur.close()\n",
    "                return resp\n",
    "\n",
    "            except Exception as e:\n",
    "                detail = '{{\"database\" : \"{0}\", \"error\" : \"{2}\",\\n \"sql\" : \"{1}\"}}'.format(\n",
    "                    self.cred[\"hostname\"], sql, e\n",
    "                )\n",
    "                self.log.debug(detail)\n",
    "                return e\n",
    "\n",
    "    def get_pg_cursor(self, cursor_type=None):\n",
    "        conn = self._connect()\n",
    "        return conn, conn.cursor(cursor_factory=cursor_type)\n",
    "\n",
    "    def qry(self, sql, commit=False):\n",
    "        \"\"\"\n",
    "        Runs a query. Creates connection if non-existent.\n",
    "        \"\"\"\n",
    "        if hasattr(self, \"conn\"):\n",
    "            try:\n",
    "                resp = self._execute(sql, commit)\n",
    "                if commit: return resp\n",
    "                else: return pd.DataFrame(resp)\n",
    "            except ValueError as e:\n",
    "                print(sql)\n",
    "                raise Exception(e)\n",
    "\n",
    "        else:\n",
    "            self.conn = self._connect()\n",
    "            resp = self._execute(sql, commit)\n",
    "            if commit:\n",
    "                return True\n",
    "            else:\n",
    "                return pd.DataFrame(resp)\n",
    "\n",
    "    def write_df_to_table(self, \n",
    "                          dataframe: pd.DataFrame,\n",
    "                          create_statement: str, \n",
    "                          schema: str, \n",
    "                          tablename: str, \n",
    "                          columns: tuple,\n",
    "                          db_engine: str,\n",
    "                          s3_bucket: str,\n",
    "                          append = True) -> int:\n",
    "        \"\"\"\n",
    "        Writes a dataframe to the target table using the create_statement.\n",
    "        Its best practice to add CREATE TABLE IF NOT EXISTS to your statement. \n",
    "        DROPS should be done seperately and explicity from this process.\n",
    "        \"\"\"\n",
    "        # create the table if it does not exist\n",
    "        if not self.qry(create_statement, commit = True):\n",
    "            raise Exception(f'Error writing {schema}.{tablename} to {self.cred[\"hostname\"]}')\n",
    "        # delete table results if append does not exist\n",
    "        if not append:\n",
    "            self.qry(f\"DELETE FROM {schema}.{tablename}\", commit = True)\n",
    "\n",
    "        if db_engine == 'postgres':\n",
    "            # prepare dataframe for efficent write\n",
    "            stream = StringIO()\n",
    "            dataframe.to_csv(stream, sep=\"\\t\", header=False, index=False, float_format='%.0f')\n",
    "            # move to beginning of stream\n",
    "            stream.seek(1)\n",
    "            contents = stream.getvalue()\n",
    "            # create psycopg2 cursor\n",
    "            cur = self.conn.cursor()\n",
    "            try:\n",
    "                cur.copy_from(\n",
    "                    stream, \n",
    "                    f'{schema}.{tablename}', \n",
    "                    null=\"\", \n",
    "                    columns=columns\n",
    "                )\n",
    "                self.conn.commit()\n",
    "            except psycopg2.errors.InFailedSqlTransaction as e:\n",
    "                self.conn.rollback()\n",
    "                raise Exception(f'Error copying to {schema}.{tablename}. Transaction block failed.')\n",
    "            # close cursor after job is complete\n",
    "            cur.close()\n",
    "            return True\n",
    "        elif db_engine == 'redshift':\n",
    "            # write dataframe to S3 bucket, also get credentials \n",
    "            bucket = S3Bucket(s3_bucket)\n",
    "            bucket.write_dataframe(dataframe, f'atb-writer/{tablename}.tsv')\n",
    "            access_key = bucket.aws_access_key_id\n",
    "            secret_access_key = bucket.aws_secret_access_key\n",
    "            # copy \n",
    "            load = f\"\"\"\n",
    "            COPY {schema}.{tablename}\n",
    "            FROM 's3://{s3_bucket}/atb-writer/{tablename}.tsv'\n",
    "            CREDENTIALS 'aws_access_key_id={access_key};aws_secret_access_key={secret_access_key}'\n",
    "            DELIMITER '\\t';\n",
    "            \"\"\"\n",
    "            self.qry(load, commit = True)\n",
    "            # delete from s3 \n",
    "            bucket.bucket.Object(\"atb-writer/{tablename}.tsv\").delete()\n",
    "            return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class DBConnector:\n",
    "    \"\"\"\n",
    "    Object that stores connections to many databases, which are created\n",
    "    from a .ini file that is passed as an object.\n",
    "    \"\"\"\n",
    "    def __init__(self, config_file, log=StreamLog()):\n",
    "        self.config = configparser.RawConfigParser()\n",
    "        self.config.read(config_file)\n",
    "        self.log = log\n",
    "        self.active_connections = {}\n",
    "        # Run func and initialize objects on self\n",
    "        self._init_database_objects()\n",
    "\n",
    "    def _init_database_objects(self):\n",
    "        criteria = [\"port\", \"database\", \"user\", \"hostname\"]\n",
    "        # review sections in config for db sections\n",
    "        for section in self.config.sections():\n",
    "            n = self.config.options(section)\n",
    "            # if the section has the criteria, store them\n",
    "            if set(criteria).issubset(set(n)):\n",
    "                bkt = {}\n",
    "                for i in criteria:\n",
    "                    p = self.config.get(section, i)\n",
    "                    bkt[i] = p\n",
    "                # allows db.section referencing\n",
    "                setattr(\n",
    "                    self, section.replace(\"-\", \"\"), DatabaseConnection(bkt, self.log)\n",
    "                )\n",
    "                self.active_connections[section] = DatabaseConnection(bkt, self.log)\n",
    "        # Check if configuration file has proper sections\n",
    "        if len(self.active_connections) == 0:\n",
    "            raise Exception(\n",
    "                \"\"\"\\n\n",
    "                Configuration file contained no Postgres sections. Please review\n",
    "                and format like below example :\n",
    "                    [dev_db]\n",
    "                    hostname = dev.yourhost.com\n",
    "                    port = 5432\n",
    "                    database = dbname \n",
    "                    user = htpeter\n",
    "                    \n",
    "                For additional help, please see documentation\n",
    "                    https://htpeter.github.io/analytics_toolbox/#Help-With-Postges-Connection-Setup\n",
    "                \"\"\"\n",
    "            )\n",
    "            \n",
    "    def add_file_logger(log_obj: LocalLog):\n",
    "        self.log = log_obj \n",
    "        return self\n",
    "\n",
    "    def close_all_conns(self):\n",
    "        counter = 0\n",
    "        conns = []\n",
    "        for i in self.active_connections.keys():\n",
    "            adj = i.replace(\"-\", \"\")\n",
    "            obj = getattr(self, adj)\n",
    "            try:\n",
    "                obj.conn.close()\n",
    "                conns.append(adj)\n",
    "                counter += 1\n",
    "            except Exception as e:\n",
    "                pass\n",
    "        print(\"\\n\\t Closed {0} connections.\\n\\t {1} \".format(str(counter), str(conns)))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return pformat(self.active_connections, indent=4)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.active_connections[item]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def move_table(table, from_db, to_db):\n",
    "    assert type(from_db) == DatabaseConnection\n",
    "    assert type(to_db) == DatabaseConnection\n",
    "    creds = {\n",
    "        \"from_host\": from_db.cred[\"hostname\"],\n",
    "        \"from_db\": from_db.cred[\"database\"],\n",
    "        \"from_user\": from_db.cred[\"user\"],\n",
    "        \"to_host\": to_db.cred[\"hostname\"],\n",
    "        \"to_db\": to_db.cred[\"database\"],\n",
    "        \"to_user\": to_db.cred[\"user\"],\n",
    "        \"table\": table,\n",
    "    }\n",
    "    os.system(\n",
    "        \"pg_dump -t {table} -h {from_host} -U {from_user} {from_db} | psql -h {to_host} -U {to_user} {to_db}\".format(\n",
    "            **creds\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "class NativeTemplateEnvironment(object):\n",
    "    \"\"\"\n",
    "    Reads files from a folder, passed during initialization, and injects values \n",
    "    from a dictionary. Usings Python native string functions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, templates_folder):\n",
    "        self.path = templates_folder\n",
    "\n",
    "    def build(self, template_name, context):\n",
    "        complete_path = self.path + \"/\" + template_name\n",
    "        # In case user passes trailing / in self.path\n",
    "        complete_path = complete_path.replace(\"//\", \"/\")\n",
    "        f = open(complete_path, \"r\")\n",
    "        skeleton = f.read()\n",
    "        f.close()\n",
    "        sql = skeleton.format(**context)\n",
    "        return sql"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
